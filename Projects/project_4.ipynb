{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN) with Python and Tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and visualization components\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# modeling components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D\n",
    "\n",
    "# losses and optimizers components\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# subclassed model components\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "# callback components\n",
    "import os\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset from tensorflow_datasets\n",
    "ds = tfds.load('mnist', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a numpy iterator\n",
    "data_iterator = ds.as_numpy_iterator()\n",
    "\n",
    "# Visualize the data\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    # Grab an image and label\n",
    "    sample = data_iterator.next()\n",
    "    ax[idx].imshow(np.squeeze(sample['image']))\n",
    "    ax[idx].title.set_text(sample['label'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all the images\n",
    "def scale_images(data): \n",
    "    image = data['image']\n",
    "    return image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the dataset through the scale_images preprocessing step\n",
    "ds = ds.map(scale_images) \n",
    "# Cache the dataset for that batch \n",
    "ds = ds.cache()\n",
    "# Shuffle it up \n",
    "ds = ds.shuffle(60000)\n",
    "# Batch into 128 images per sample\n",
    "ds = ds.batch(128)\n",
    "# Reduces the likelihood of bottlenecking \n",
    "ds = ds.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.as_numpy_iterator().next().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()                       # define our model\n",
    "    model.add(Dense(7*7*128, input_dim=128))   # add Dense layer with random noise as input\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "    model.add(Reshape((7,7,128)))              # reshape to 17*17*128\n",
    "\n",
    "    # Upsampling block - 1\n",
    "    model.add(UpSampling2D())                  # layer used to increase the spatial resolution of the input\n",
    "    model.add(Conv2D(128, 5, padding='same'))  # convolutional nn layer with 128 units, kernel size 5x5 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Upsampling block - 2\n",
    "    model.add(UpSampling2D())                  # layer used to increase the spatial resolution of the input\n",
    "    model.add(Conv2D(128, 5, padding='same'))  # convolutional nn layer with 128 units, kernel size 5x5 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Downsampling block - 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))  # convolutional nn layer with 128 units, kernel size 4x4 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Downsampling block - 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))  # convolutional nn layer with 128 units, kernel size 4x4 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # convolutional nn layer to change to 1 channel,kernel size 4x4, same padding and a sigmoid activation this time\n",
    "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator summary\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 4 new images\n",
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "\n",
    "# Setup the subplot formatting \n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# Loop 4 times and get images \n",
    "for idx, img in enumerate(img): \n",
    "    # Plot the image using a specific subplot \n",
    "    ax[idx].imshow(np.squeeze(img))\n",
    "    ax[idx].title.set_text(idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv Block\n",
    "    model.add(Conv2D(32, 5, input_shape = (28,28,1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Second Conv Block\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Third Conv Block\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Fourth Conv Block\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten then pass to dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator summary\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 4 images\n",
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "# use the discriminator to predict the images made by the generator\n",
    "discriminator.predict(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup losses and optimizers\n",
    "g_opt = Adam(learning_rate=0.0001) \n",
    "d_opt = Adam(learning_rate=0.00001) \n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build subclassed model\n",
    "class numbersGAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # Pass through args and kwargs to base class \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for gen and disc\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # Get the data \n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as d_tape: \n",
    "            # Pass the real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            # Create labels for real and fakes images\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            # Add some noise to the TRUE outputs\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            # Calculate loss - BINARYCROSS \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Apply backpropagation - nn learn \n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as g_tape: \n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
    "                                        \n",
    "            # Create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            # Calculate loss - trick to training to fake out the discriminator\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of subclassed model\n",
    "numgan = numbersGAN(generator, discriminator)\n",
    "# Compile the model\n",
    "numgan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('data/project_4/images/', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend 1500-2000 epochs\n",
    "hist = numgan.fit(ds, epochs=10, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revew model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='d_loss')\n",
    "plt.plot(hist.history['g_loss'], label='g_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new images\n",
    "imgs = generator.predict(tf.random.normal((16, 128, 1)))\n",
    "# plot the generated images\n",
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\n",
    "for r in range(4): \n",
    "    for c in range(4): \n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('data/project_4/model/generator.h5')\n",
    "discriminator.save('data/project_4/model/discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
