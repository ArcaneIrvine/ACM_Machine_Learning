{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove faulty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/project_3/data'\n",
    "image_extensions = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "# loop through all our data\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            # load image\n",
    "            img = cv2.imread(image_path)\n",
    "            # check if the extension fits out list of allowed extensions\n",
    "            tip = imghdr.what(image_path)\n",
    "            # if not remove that image\n",
    "            if tip not in image_extensions:\n",
    "                print('image not in extensions list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('issue with image {}'.format(image_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataset on the fly using tf.keras which will automatically create a dataset from our images + resize\n",
    "data = tf.keras.utils.image_dataset_from_directory('data/project_3/data', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to a numpy iterator (allows us to access our data pipeline since the data is not preloaded in the memory it is a generator)\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "\n",
    "# get a batch from the iterator (allows us to access our data pipeline itself)\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# visualize a batch\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-proccess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data using map function (x is our image and y is the key/label)\n",
    "data = data.map(lambda x, y: (x/255, y))\n",
    "# convert it to a numpy iterator (allows us to access our data pipeline)\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "# get a batch from the iterator (allows us to access our data pipeline itself)\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.2)\n",
    "validation_size = int(len(data)*.3)\n",
    "test_size = int(len(data)*.1)+1\n",
    "\n",
    "# use take and skip methods (how many batches we want to allocate for each split we declared)\n",
    "train = data.take(train_size)\n",
    "validation = data.skip(train_size).take(validation_size)\n",
    "test_size = data.skip(train_size+validation_size).take(test_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare our model using the Sequential api\n",
    "model = Sequential()\n",
    "# add layers to the model\n",
    "\n",
    "\"\"\"\n",
    "add a convolution with 16 filters 3x3 in size and a stride of 1. Relu activation\n",
    "that will convert any negative values to 0 and anything positive will remain unchanged.\n",
    "Then also define what the input shape looks like so 256x256 pixels wired by 3 channels deep \n",
    "(basically scans over an image and tries to condense or extract the relevant information \n",
    "inside of that image to make an output classification)\n",
    "\"\"\"\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "# apply a Max Pooling layer which is going to take the max value after the relu activation and return that value\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# similarly add a convolution with 32 filters this time and relu activation\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# similarly add a convolution with 16 filters again this time and relu activation\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# flatten the data down\n",
    "model.add(Flatten())\n",
    "\n",
    "# add fully connected Dense layers with 256 neurons and relu activation\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# add a final Dense layer with 1 neuron to get a single output that is going to represent 0 or 1 with a sigmoid activation (which will match our classes)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile our model with adam optimizer and define what our losses are and an accuracy metric\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'data/project_3/logs'\n",
    "# used for logging out the model training as its training, so we can come back and see how it performed at a particular time\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# fit the model\n",
    "hist = model.fit(train, epochs=10, validation_data=validation, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our model performance using matplotlib\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our model accuracy using matplotlib\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some instances\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "# loop through each batch in our test data and make a prediction\n",
    "for batch in test_size.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    yhat = model.predict(x)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on some images it has not seen before\n",
    "img = cv2.imread('data/project_3/test/hellebore_test.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "resized_img = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resized_img.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed into the model (model expects a batch and not a single image, so we need to encapsulate it inside another set of arrays)\n",
    "np.expand_dims(resized_img, 0)\n",
    "result = model.predict(np.expand_dims(resized_img/255, 0))\n",
    "print(result)\n",
    "if result > 0.5:\n",
    "    print(f'Predicted class is mountain larual')\n",
    "else:\n",
    "    print(f'Predicted class is hellebore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(os.path.join('data/project_3/models', 'poisonous_flowers.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
